## Basic

**Вектор / Vector** - преобразование в пространстве (преобразование аргументов)

<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/70a031c92741d94ef93fa6613a3f993940c41943>

**Скаляр** - масштабирует вектор (2 - удвоение)

**Длинна вектора** - |v| = sqrt(x1^2+x2^2+...xn^2)

**Геометрическое определение векторов**

Типы:
- свободные (два вектора равны если они одинаковой длинны и совпадают по направлению) - чаще всего используется
- скользящие (два вектора равны если выполняется условие свободных плюс точки их начала лежат на одной прямой)
- связанные (два вектора равны если выполняется условие свободных плюс точки их начала совпадают)

**Сложение векторов** - Суммой двух векторов u и v называется третий вектор w, проведенный из начала u к концу v, если начало вектора v совпадает с концом вектора u. Сложение векторов выполняется по правилу треугольника или по правилу параллелограмма. w=u+v
Это последовательное преобразование, сначало первого вектора, потом второго, в результате получаем новый вектор.

<img src=http://www.math24.ru/images/vector-addition2.jpg>

**Basic vectors (базис)** - набор векторов в векторном пространстве, такой, что любой вектор этого пространства может быть единственным образом представлен в виде линейной комбинации векторов из этого набора. Векторы базиса называются базисными векторами. 
Это основные(начальные) векторы в которых происходит преобразование. Еденичные векторы (i,j). Определяют систему координат.

<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/3d_two_bases_same_vector.svg/195px-3d_two_bases_same_vector.svg.png>

Любой вектор может быть представлен линейной комбинацией basic vectors

**Линейная комбинация** - выражение, построенное на множестве элементов путём умножения каждого элемента на коэффициенты с последующим сложением результатов
av + vw

<img src=https://function-x.ru/image/vect_sum.jpg>

**Span** (размерность) - все возможные линейные комбинации.
В двухмерном пространстве av + bw двух векторов (если они не лежат на одной линии), span - это вся плоскость. Комбинацией a и b можно достать до любой точке в пространстве. Для одномерного массива - это все точки на прямой.

**Линейное преобразование**
Это функция которая берет вектор как аргумент и возвращает преобразованный вектор. При линейном приобразовании изменяются basic vectors. Тоесть вектор который преобразовывается переходит в новую систему координат (с новыми базисными векторами)

- геометрически - преобразование при котором все линии остаються паралельны и равноотдаленны, а начало координат не меняется.

- мат:
	- L(v+w) = L(v) + L(w) - additivity (адативность)
	- L(c*v) = c * L(v) - scaling (однородность)
	
<img src=http://ru.solverbook.com/wp-content/ql-cache/quicklatex.com-eb7e8c525c1007d9bf4111bc3699f761_l3.svg>

(a b) * (x) = x*(a) + y*(b) = (xa+yb)
(c d)   (y)     (b)     (d)   (xc+yd) 

## Матрицы
Матрицы - это одно из возможных описаний линейного преобразования (для basic vectors), где столбцы - его координаты

**Линейная независимость / linear independent** - все вектора находяться в разных измерениях (не лежат на одной прямой)
a set of vectors is said to be **linearly dependent** if at least one of the vectors in the set can be defined as a linear combination of the others; if no vector in the set can be written in this way, then the vectors are said to be **linearly independent**.

**Rank** (rgA) - количество измерений  (по кол-ву колонок). Full Rank - когда все измерения используются, нет лин. зависимых векторов.

**Kernel** - пространство всех векторов, которые после преобразовани становяться нулевыми (схлопываются в начало координат)

**Inverse transformation** - обратное преобразование. Когда мы знаем какое было исходное преобразование (матрицу преобразования) и резуьтирующий вектор, то с помощью inverse transformation можем найти исходный вектор. (используется для решения лин уравнений)

![invers_transf](./content/inverse_transf.png)

**Non square matrix** - (m-by-n matrices for which m ≠ n) do not have an inverse. Трансформация между измерениями (2x3) - 2-х мерная мтраца представленная в 3-х мерном пространстве

### Операции над матрицами

**Детерминант** - det - это кооэфициент определяющий во сколько раз измениться область (прямая, площадь, обьем ...) после преобразования. Знак детерминанта определяет было ли отражение при преобразовании.

<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/5b2e40d390e1d26039aabee44c7d1d86c8755232>

<img src=https://commons.wikimedia.org/wiki/File:Area_parallellogram_as_determinant.svg?uselang=ru>

Если det = 0, размерность матрицы уменьшается (плоскость -> в прямую или даже в точку), также это означет что в матрице есть линейно зависимые векторы.

**Взятие обратной матрицы** - такая матрица A−1, при умножении на которую исходная матрица A даёт в результате единичную матрицу E: 

<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/597164354f85c384a157fb220ba8c348de0a69f3>

**Произведение матриц / Matrix multiplication** - это последовательное преобразование, в результате получаем матрицу. Порядок имеет значение! Умножение выполняется с лева на право.
Умножать можно матрицы, если число столбцов первой матрицы равно числу строк второй матрицы.
В результате получится матрица, число строк которой равно числу строк первой матрицы, а число столбцов равно числу столбцов второй матрицы.

![matrix_prod](./content/matrix_prod.png)

Свойства произведения матриц:

<img src=https://educon.by/images/formuly/allmath/304.png>

При умножении на матрицу, вторая матрица рассматривается как векторы (x, v), (y, w), которые преобразовываются первой матрицей (a b / c d).

**Сложение матриц**

![matrix_add](./content/matrix_add.png)

**Транспонирование матриц** - столбцы становяться строками. При транспонировании det не меняется.

Свойства транспонирования матриц:

<img src=https://educon.by/images/formuly/allmath/303.png>

**Скалярное произведение / Dot product**

Скалярное произведение - это преобразование в одномерное пространство. Определяется как произведение длинны вектора на проекцию второго вектора на него.

![dot_product](./content/dot_product.png)

A*B = |A|*|B|*cosL

|A|,|B| -  длины векторов
cosL - косинус угла между векторами

Зная скалярное произведение векторов и их длины мы можем найти угол между векторами - arccos(A*B/|A|*|B|)

**Вектроное произведение /  Cross product**
в результате получаем вектор перпендикулярный паралелограмму, с длинной равняющейся площади этого паралелограмма (det). Используется правило правой руки.

<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Right_hand_rule_cross_product.svg/220px-Right_hand_rule_cross_product.svg.png>
![cross_product](./content/cross_product.png)

## Собственный вектор / Eigen vector 

Собственный вектор - вектор, который при преобразовании не меняет свое расположение, его span не меняется. Он только растягивается или сужается.

<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Eigenvalue_equation.svg/250px-Eigenvalue_equation.svg.png>

**Собственное значение / eigen value** - определяет на сколько растянулся или сузился собственный вектор после преобразования.

<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/a6a81419426d308a21f35ebeb5d686afbcc5a62c>
A - матрица, v - собственный вектор, Y - собственное значение
Преобразование вектора v матрицей А - ровнослиьно умножению вектора v на eigen value. (Так как собственный вектор при преобразовании не перемещается)


![eigen_value](./content/eigen_value.png)

*Example:*

![eigen_value_example](./content/eigen_value_example.png)


**Eigen basis** - eigen vector становяться eigen basis когда он лежит на осях (Диагональная матрица)

**Diagonal matrix** - is a matrix in which the entries outside the main diagonal are all zero.

<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/904022c91f61c1cf3f78376a36e1b1d4b05c1f5d>

Это значит что все ее собственные вектора лежат на базисных векторах (на осях)

Чтобы преобразовать матрицу в диагональную, нужно использовать собственный вектор как новые базисные вектора (преобразование изменением базисных векторов)

A^-1 * M * A, где А = это матрица из собственных вектор

 Но это не всегда возможно, так как должны быть хотя бы два eigen vectors.

## Change of basis

Когда мы хотим перейти с одной сист. координат в другую. Изменить basis vectors для определенного преобразования.
 Формула:
A^-1 * M * A

М - матрица преобразования
А - basis vectors

Example:

![ch_basis_vectors](./content/ch_basis_vectors.png)

*Коментарий:* тоесть чтобы выполнить преобразование матрицей М, но в новых координатах, новые basis vectors, мы можем умножить нашу матрицу М на A^-1 * M * A, где А - это матрица из eigen vectors.

## --

Функции тоже могут быть линейными, тоесть выполнять линейное преобразование. Например производная - это линейное преобразование.

 <table style="width:100%">
  <tr>
    <th>Linear Algebra</th>
    <th>Functions</th>
  </tr>
  <tr>
    <td>Linear transformation</td>
    <td>Linear operation</td>
  </tr>
  <tr>
    <td>Dot product</td>
    <td>Linear product</td>
  </tr>
  <tr>
    <td>Eigen vector</td>
    <td>Eigen fuction</td>
  </tr>
</table> 